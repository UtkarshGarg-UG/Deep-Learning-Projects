{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16386a60-d458-4aeb-975e-05ea2ec1da73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "import time\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "#from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "from torch import nn\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import torchmetrics\n",
    "import wandb\n",
    "import re\n",
    "# Setting the seed\n",
    "pl.seed_everything(1)\n",
    "torch.set_printoptions(edgeitems=30)\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_layer import Vocabulary, Train_Dataset, Validation_Dataset, MyCollate, DataModule\n",
    " \n",
    "\n",
    "DEVICE = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921fbfff-8264-441d-b97f-f98b9dd98f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a9a102-2e6a-4d1f-9347-70cf18e766fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of train:  900000\n",
      "len of val:  100000\n"
     ]
    }
   ],
   "source": [
    "data_module = DataModule('../train.txt', source_column = 'factors', \n",
    "                         target_column = 'expressions', batch_size = 512)\n",
    "\n",
    "data_module.setup(val_frac = 0.1)\n",
    "\n",
    "train_iterator = data_module.train_dataloader()\n",
    "valid_iterator = data_module.val_dataloader()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3489226-33ba-4e9b-880e-e90ff1b0f707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Checkpoint ...\n",
      "Loading Model...\n",
      "Loading Vocabulary...\n",
      "Predicting Factors ....\n",
      "100%|███████████████████████████████████████| 1000/1000 [00:49<00:00, 20.29it/s]\n",
      "Score: 0.999\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1dd279f-a1cc-44fa-b0ce-2e26efa1e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.val.to_csv('val.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "940dbb8b-ca42-44ad-a4d7-2fcd413ba78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model hyperparameters\n",
    "# # Model hyperparameters\n",
    "# src_vocab_size = len(data_module.train_dataset.source_vocab.itos)\n",
    "# trg_vocab_size = len(data_module.train_dataset.target_vocab.itos)\n",
    "# embedding_size = 128\n",
    "# num_heads = 4\n",
    "# num_encoder_layers = 3\n",
    "# num_decoder_layers = 3\n",
    "# dropout = 0.10\n",
    "# max_len = 40\n",
    "# forward_expansion = 256\n",
    "# src_pad_idx = data_module.train_dataset.source_vocab.stoi[\"<PAD>\"]\n",
    "# learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9817b652-a9e2-4572-a7fc-aaa398e6b900",
   "metadata": {},
   "source": [
    "### Encoder Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4100fa23-0869-42c2-a9ed-c8be42a158d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Encoder, Decoder, Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b0017f1-0b82-480f-8fa5-54e1a86ed64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'INPUT_DIM': len(data_module.train_dataset.source_vocab.itos),\n",
    "    'OUTPUT_DIM': len(data_module.train_dataset.target_vocab.itos),\n",
    "    'HID_DIM' : 256,\n",
    "    'ENC_LAYERS' : 3,\n",
    "    'DEC_LAYERS' : 3,\n",
    "    'ENC_HEADS' : 4,\n",
    "    'DEC_HEADS' : 4,\n",
    "    'ENC_PF_DIM' : 512,\n",
    "    'DEC_PF_DIM' : 512,\n",
    "    'ENC_DROPOUT' : 0.1,\n",
    "    'DEC_DROPOUT' : 0.1\n",
    "}\n",
    "\n",
    "enc = Encoder(model_params['INPUT_DIM'], \n",
    "              model_params['HID_DIM'], \n",
    "              model_params['ENC_LAYERS'], \n",
    "              model_params['ENC_HEADS'], \n",
    "              model_params['ENC_PF_DIM'], \n",
    "              model_params['ENC_DROPOUT'], \n",
    "              DEVICE)\n",
    "\n",
    "dec = Decoder(model_params['OUTPUT_DIM'], \n",
    "              model_params['HID_DIM'], \n",
    "              model_params['DEC_LAYERS'], \n",
    "              model_params['DEC_HEADS'], \n",
    "              model_params['DEC_PF_DIM'], \n",
    "              model_params['DEC_DROPOUT'], \n",
    "              DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdaeaf99-1557-467d-ab9f-22a98f73dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_PAD_IDX = data_module.train_dataset.source_vocab.stoi['<PAD>']\n",
    "TRG_PAD_IDX = data_module.train_dataset.target_vocab.stoi['<PAD>']\n",
    "\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, DEVICE).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5065853-bfe8-48ba-b2ca-3bdae1f5f0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e11c0928-eca7-4908-9e39-3255e992c172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 4,032,548 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83191629-d417-4f7a-bbaf-55d150e069ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccd9e850-9199-48d4-8d80-1ae500d210c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.apply(initialize_weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "551bdb23-db04-4478-8986-09ecffbffa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19e0c621-2d02-47d3-8d1f-27435e3e1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()#(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f999ff69-04c9-4276-9c6f-017faac1baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Engine import train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ccd2cb3-4feb-4935-aa9e-d9426c3dd276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac41290e-16f2-4609-83f5-63782aa40377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21955b42-184d-4f6e-972f-a6b2b3f7d383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss for last 0 steps: 4.32685\n",
      "Avg train sent acc for last 0 steps: 0.00\n",
      "Avg train loss for last 500 steps: 0.62760\n",
      "Avg train sent acc for last 500 steps: 0.04\n",
      "Avg train loss for last 1000 steps: 0.47638\n",
      "Avg train sent acc for last 1000 steps: 0.10\n",
      "Avg train loss for last 1500 steps: 0.39051\n",
      "Avg train sent acc for last 1500 steps: 0.15\n",
      "Epoch: 01 | Time: 2m 57s\n",
      "\tTrain Loss: 0.357 | Train PPL:   1.429\n",
      "\t Val. Loss: 0.117 |  Val. PPL:   1.124\n",
      "\t Val. Sent Accuracy: 0.4\n",
      "Avg train loss for last 0 steps: 0.15662\n",
      "Avg train sent acc for last 0 steps: 0.34\n",
      "Avg train loss for last 500 steps: 0.13204\n",
      "Avg train sent acc for last 500 steps: 0.37\n",
      "Avg train loss for last 1000 steps: 0.11997\n",
      "Avg train sent acc for last 1000 steps: 0.39\n",
      "Avg train loss for last 1500 steps: 0.10998\n",
      "Avg train sent acc for last 1500 steps: 0.41\n",
      "Epoch: 02 | Time: 2m 55s\n",
      "\tTrain Loss: 0.106 | Train PPL:   1.111\n",
      "\t Val. Loss: 0.058 |  Val. PPL:   1.060\n",
      "\t Val. Sent Accuracy: 0.6\n",
      "Avg train loss for last 0 steps: 0.07537\n",
      "Avg train sent acc for last 0 steps: 0.50\n",
      "Avg train loss for last 500 steps: 0.07329\n",
      "Avg train sent acc for last 500 steps: 0.50\n",
      "Avg train loss for last 1000 steps: 0.06913\n",
      "Avg train sent acc for last 1000 steps: 0.52\n",
      "Avg train loss for last 1500 steps: 0.06564\n",
      "Avg train sent acc for last 1500 steps: 0.53\n",
      "Epoch: 03 | Time: 2m 52s\n",
      "\tTrain Loss: 0.064 | Train PPL:   1.066\n",
      "\t Val. Loss: 0.035 |  Val. PPL:   1.036\n",
      "\t Val. Sent Accuracy: 0.7\n",
      "Avg train loss for last 0 steps: 0.05484\n",
      "Avg train sent acc for last 0 steps: 0.60\n",
      "Avg train loss for last 500 steps: 0.04996\n",
      "Avg train sent acc for last 500 steps: 0.61\n",
      "Avg train loss for last 1000 steps: 0.04767\n",
      "Avg train sent acc for last 1000 steps: 0.63\n",
      "Avg train loss for last 1500 steps: 0.04539\n",
      "Avg train sent acc for last 1500 steps: 0.64\n",
      "Epoch: 04 | Time: 2m 53s\n",
      "\tTrain Loss: 0.044 | Train PPL:   1.045\n",
      "\t Val. Loss: 0.023 |  Val. PPL:   1.023\n",
      "\t Val. Sent Accuracy: 0.8\n",
      "Avg train loss for last 0 steps: 0.03947\n",
      "Avg train sent acc for last 0 steps: 0.66\n",
      "Avg train loss for last 500 steps: 0.03562\n",
      "Avg train sent acc for last 500 steps: 0.71\n",
      "Avg train loss for last 1000 steps: 0.03473\n",
      "Avg train sent acc for last 1000 steps: 0.71\n",
      "Avg train loss for last 1500 steps: 0.03374\n",
      "Avg train sent acc for last 1500 steps: 0.72\n",
      "Epoch: 05 | Time: 2m 54s\n",
      "\tTrain Loss: 0.033 | Train PPL:   1.034\n",
      "\t Val. Loss: 0.018 |  Val. PPL:   1.019\n",
      "\t Val. Sent Accuracy: 0.8\n",
      "Avg train loss for last 0 steps: 0.02946\n",
      "Avg train sent acc for last 0 steps: 0.75\n",
      "Avg train loss for last 500 steps: 0.02910\n",
      "Avg train sent acc for last 500 steps: 0.75\n",
      "Avg train loss for last 1000 steps: 0.02900\n",
      "Avg train sent acc for last 1000 steps: 0.75\n",
      "Avg train loss for last 1500 steps: 0.02814\n",
      "Avg train sent acc for last 1500 steps: 0.76\n",
      "Epoch: 06 | Time: 2m 53s\n",
      "\tTrain Loss: 0.028 | Train PPL:   1.028\n",
      "\t Val. Loss: 0.015 |  Val. PPL:   1.015\n",
      "\t Val. Sent Accuracy: 0.9\n",
      "Avg train loss for last 0 steps: 0.02637\n",
      "Avg train sent acc for last 0 steps: 0.76\n",
      "Avg train loss for last 500 steps: 0.02476\n",
      "Avg train sent acc for last 500 steps: 0.78\n",
      "Avg train loss for last 1000 steps: 0.02420\n",
      "Avg train sent acc for last 1000 steps: 0.79\n",
      "Avg train loss for last 1500 steps: 0.02360\n",
      "Avg train sent acc for last 1500 steps: 0.79\n",
      "Epoch: 07 | Time: 2m 53s\n",
      "\tTrain Loss: 0.023 | Train PPL:   1.024\n",
      "\t Val. Loss: 0.012 |  Val. PPL:   1.012\n",
      "\t Val. Sent Accuracy: 0.9\n",
      "Avg train loss for last 0 steps: 0.02277\n",
      "Avg train sent acc for last 0 steps: 0.81\n",
      "Avg train loss for last 500 steps: 0.02248\n",
      "Avg train sent acc for last 500 steps: 0.81\n",
      "Avg train loss for last 1000 steps: 0.02166\n",
      "Avg train sent acc for last 1000 steps: 0.81\n",
      "Avg train loss for last 1500 steps: 0.02118\n",
      "Avg train sent acc for last 1500 steps: 0.82\n",
      "Epoch: 08 | Time: 2m 53s\n",
      "\tTrain Loss: 0.021 | Train PPL:   1.021\n",
      "\t Val. Loss: 0.010 |  Val. PPL:   1.010\n",
      "\t Val. Sent Accuracy: 0.9\n",
      "Avg train loss for last 0 steps: 0.02004\n",
      "Avg train sent acc for last 0 steps: 0.82\n",
      "Avg train loss for last 500 steps: 0.01946\n",
      "Avg train sent acc for last 500 steps: 0.83\n",
      "Avg train loss for last 1000 steps: 0.01887\n",
      "Avg train sent acc for last 1000 steps: 0.84\n",
      "Avg train loss for last 1500 steps: 0.01882\n",
      "Avg train sent acc for last 1500 steps: 0.84\n",
      "Epoch: 09 | Time: 2m 50s\n",
      "\tTrain Loss: 0.019 | Train PPL:   1.019\n",
      "\t Val. Loss: 0.008 |  Val. PPL:   1.009\n",
      "\t Val. Sent Accuracy: 0.9\n",
      "Avg train loss for last 0 steps: 0.01959\n",
      "Avg train sent acc for last 0 steps: 0.82\n",
      "Avg train loss for last 500 steps: 0.01752\n",
      "Avg train sent acc for last 500 steps: 0.85\n",
      "Avg train loss for last 1000 steps: 0.01711\n",
      "Avg train sent acc for last 1000 steps: 0.85\n",
      "Avg train loss for last 1500 steps: 0.01710\n",
      "Avg train sent acc for last 1500 steps: 0.85\n",
      "Epoch: 10 | Time: 2m 47s\n",
      "\tTrain Loss: 0.017 | Train PPL:   1.017\n",
      "\t Val. Loss: 0.007 |  Val. PPL:   1.007\n",
      "\t Val. Sent Accuracy: 0.9\n",
      "Avg train loss for last 0 steps: 0.01398\n",
      "Avg train sent acc for last 0 steps: 0.88\n",
      "Avg train loss for last 500 steps: 0.01565\n",
      "Avg train sent acc for last 500 steps: 0.86\n",
      "Avg train loss for last 1000 steps: 0.01551\n",
      "Avg train sent acc for last 1000 steps: 0.86\n",
      "Avg train loss for last 1500 steps: 0.01545\n",
      "Avg train sent acc for last 1500 steps: 0.87\n",
      "Epoch: 11 | Time: 2m 54s\n",
      "\tTrain Loss: 0.015 | Train PPL:   1.015\n",
      "\t Val. Loss: 0.007 |  Val. PPL:   1.007\n",
      "\t Val. Sent Accuracy: 0.9\n",
      "Avg train loss for last 0 steps: 0.01208\n",
      "Avg train sent acc for last 0 steps: 0.88\n",
      "Avg train loss for last 500 steps: 0.01403\n",
      "Avg train sent acc for last 500 steps: 0.88\n",
      "Avg train loss for last 1000 steps: 0.01428\n",
      "Avg train sent acc for last 1000 steps: 0.88\n",
      "Avg train loss for last 1500 steps: 0.01423\n",
      "Avg train sent acc for last 1500 steps: 0.88\n",
      "Epoch: 12 | Time: 2m 53s\n",
      "\tTrain Loss: 0.014 | Train PPL:   1.014\n",
      "\t Val. Loss: 0.006 |  Val. PPL:   1.006\n",
      "\t Val. Sent Accuracy: 1.0\n",
      "Avg train loss for last 0 steps: 0.01162\n",
      "Avg train sent acc for last 0 steps: 0.91\n",
      "Avg train loss for last 500 steps: 0.01368\n",
      "Avg train sent acc for last 500 steps: 0.88\n",
      "Avg train loss for last 1000 steps: 0.01354\n",
      "Avg train sent acc for last 1000 steps: 0.88\n",
      "Avg train loss for last 1500 steps: 0.01339\n",
      "Avg train sent acc for last 1500 steps: 0.89\n",
      "Epoch: 13 | Time: 2m 59s\n",
      "\tTrain Loss: 0.013 | Train PPL:   1.013\n",
      "\t Val. Loss: 0.005 |  Val. PPL:   1.005\n",
      "\t Val. Sent Accuracy: 1.0\n",
      "Avg train loss for last 0 steps: 0.01423\n",
      "Avg train sent acc for last 0 steps: 0.88\n",
      "Avg train loss for last 500 steps: 0.01200\n",
      "Avg train sent acc for last 500 steps: 0.90\n",
      "Avg train loss for last 1000 steps: 0.01165\n",
      "Avg train sent acc for last 1000 steps: 0.90\n",
      "Avg train loss for last 1500 steps: 0.01180\n",
      "Avg train sent acc for last 1500 steps: 0.90\n",
      "Epoch: 14 | Time: 2m 56s\n",
      "\tTrain Loss: 0.012 | Train PPL:   1.012\n",
      "\t Val. Loss: 0.005 |  Val. PPL:   1.005\n",
      "\t Val. Sent Accuracy: 1.0\n",
      "Avg train loss for last 0 steps: 0.01181\n",
      "Avg train sent acc for last 0 steps: 0.90\n",
      "Avg train loss for last 500 steps: 0.01085\n",
      "Avg train sent acc for last 500 steps: 0.91\n",
      "Avg train loss for last 1000 steps: 0.01071\n",
      "Avg train sent acc for last 1000 steps: 0.91\n",
      "Avg train loss for last 1500 steps: 0.01083\n",
      "Avg train sent acc for last 1500 steps: 0.91\n",
      "Epoch: 15 | Time: 2m 54s\n",
      "\tTrain Loss: 0.011 | Train PPL:   1.011\n",
      "\t Val. Loss: 0.003 |  Val. PPL:   1.003\n",
      "\t Val. Sent Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 15\n",
    "CLIP = 1\n",
    "early_stopping_counter = 0\n",
    "early_stopping_limit = 0\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, DEVICE)\n",
    "    valid_loss, val_sent_acc = evaluate(model, valid_iterator, criterion, DEVICE)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        early_stopping_counter = 0\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save({'state_dict': model.state_dict(),\n",
    "                    'model_params': model_params,\n",
    "                    'source_stoi': data_module.train_dataset.source_vocab.stoi,\n",
    "                    'source_itos': data_module.train_dataset.source_vocab.itos,\n",
    "                    'target_stoi': data_module.train_dataset.target_vocab.stoi,\n",
    "                    'target_itos': data_module.train_dataset.target_vocab.itos}, 'tut7-model.pt')\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= early_stopping_limit:\n",
    "            print(f'Loss did not reduce for last {early_stopping_counter} epochs. Stopped training..'\n",
    "            break\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "    print(f'\\t Val. Sent Accuracy: {val_sent_acc:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac02bc5d-1e05-4ad6-9379-90e9a3ab9050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load_model, translate_sentence\n",
    "import torch\n",
    "import pandas as pd\n",
    "from data_layer import Vocabulary, Train_Dataset, Validation_Dataset, MyCollate, DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "860d3ab9-5c98-42ab-9307-d8fec5006ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using split ratio of 0.1 for train val split\n",
      "len of train:  900000\n",
      "len of val:  100000\n"
     ]
    }
   ],
   "source": [
    "data_module = DataModule('train.txt', source_column='factors', \n",
    "                             target_column = 'expressions', batch_size=512)\n",
    "    \n",
    "print(f'Using split ratio of {0.1} for train val split')\n",
    "data_module.setup(val_frac = 0.1)\n",
    "class Evaluation:\n",
    "    def __init__(self, device, checkpoint_path):\n",
    "        self.device = device\n",
    "        print('Loading Checkpoint ...')\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        print('Loading Model...')\n",
    "        self.model = load_model(checkpoint, device)\n",
    "        print('Loading Vocabulary...')\n",
    "        self.source_stoi = checkpoint['source_stoi']\n",
    "        self.source_itos = checkpoint['source_itos']\n",
    "        self.target_stoi = checkpoint['target_stoi']\n",
    "        self.target_itos = checkpoint['target_itos']\n",
    "    \n",
    "                 \n",
    "    def predict(self, factor: str):\n",
    "\n",
    "        expansion = translate_sentence(factor, self.source_stoi, self.source_itos, self.target_stoi,\n",
    "                                               self.target_itos, self.model, self.device, max_len = 30)\n",
    "        return expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "087ca28e-2169-4c59-bac3-65c794a624ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Checkpoint ...\n",
      "Loading Model...\n",
      "Loading Vocabulary...\n",
      "Predicting Factors ....\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "checkpoint_path = 'checkpoints/checkpoint.pt'\n",
    "\n",
    "evaluation = Evaluation(device, checkpoint_path)\n",
    "print(\"Predicting Factors ....\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205ae009-5bc3-4af9-b4c9-dc96a9d6d695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-9*n-22)*(3*n-23) -27*n**2+141*n+506 -27*n**2+131*n+506\n",
      "(3*t+29)*(8*t-31) 24*t**2+139*t-899 24*t**2+119*t-899\n",
      "(-7*i-13)*(5*i-19) -35*i**2+68*i+247 -35*i**2+78*i+247\n",
      "(3*s-23)*(5*s+29) 15*s**2-28*s-667 15*s**2-38*s-667\n",
      "(29-7*tan(i))*(-5*tan(i)-27) 35*tan(i)**2+44*tan(i)-783 35*tan(i)**2+34*tan(i)-783\n",
      "(-9*t-32)*(6*t+5) -54*t**2-237*t-160 -54*t**2-257*t-160\n",
      "(-9*n-27)*(-7*n-9) 63*n**2+270*n+243 63*n**2+280*n+243\n",
      "(30-8*tan(n))*(-3*tan(n)-30) 24*tan(n)**2+150*tan(n)-900 24*tan(n)**2+130*tan(n)-900\n",
      "(-8*y-16)*(-7*y-32) 56*y**2+368*y+512 56*y**2+388*y+512\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "data_module.val = data_module.val.sample(frac=1).reset_index(drop=True)\n",
    "for i in range(len(data_module.val)):\n",
    "    factor = data_module.val.loc[i,'factors']\n",
    "    expression =  data_module.val.loc[i,'expressions']\n",
    "    pred = evaluation.predict(factor)\n",
    "    if pred == expression:\n",
    "        c+=1\n",
    "    else:\n",
    "        print(factor, expression, pred)\n",
    "    if i>10000:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d97b4-8205-4e76-ab00-7818e0ce96fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c/ (i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a5be0d-9c3d-4edc-9ddf-c7650511fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 4, n_cols = 2):\n",
    "    \n",
    "    assert n_rows * n_cols == n_heads\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,25))\n",
    "    \n",
    "    for i in range(n_heads):\n",
    "        \n",
    "        ax = fig.add_subplot(n_rows, n_cols, i+1)\n",
    "        \n",
    "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
    "\n",
    "        cax = ax.matshow(_attention, cmap='bone')\n",
    "\n",
    "        ax.tick_params(labelsize=12)\n",
    "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
    "                           rotation=45)\n",
    "        ax.set_yticklabels(['']+translation)\n",
    "\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00a8516-b464-4ff4-b724-fa5780fc9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f536a-2933-4e11-82f6-035c1fccd8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = '(-4*n-14)*(2*n-2)'\n",
    "src, translation, attention = translate_sentence(sent1, source_stoi, source_itos, target_stoi, target_itos, model, device, max_len = 30)\n",
    "\n",
    "display_attention(src, translation, attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1eaa68-b5f5-4ae4-a7f4-7cdabf468d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae87f76a-fe9e-48a1-afa3-be53eec4f801",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = torch.load('checkpoints/checkpoint.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9162afb-0681-45b9-9129-bc215ac0753c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['state_dict', 'model_params', 'source_stoi', 'source_itos', 'target_stoi', 'target_itos'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10270f9e-4fbf-482b-aaac-af91d649002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ch['state_dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7681af-5071-47e1-abd7-97d3be04bc9a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f717a0fd-61dd-466e-84af-417aa7c086e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Checkpoint ...\n",
      "Loading Model...\n",
      "Loading Vocabulary...\n",
      "Predicting Factors ....\n",
      "100%|███████████████████████████████████████████| 25/25 [00:02<00:00, 10.25it/s]\n",
      "Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "!python main.py -t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6622069e-4f5e-49d4-a6f9-0e2b24c0199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 freeze > requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13560589-d54b-431f-a101-a5ec158e23c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-summary\n",
      "  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: torch-summary\n",
      "Successfully installed torch-summary-1.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7789b250-61e1-4dfb-8f14-c31e1aff65df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a1dd0cf-c598-44e6-bcbe-f3f3e24f875e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "├─Encoder: 1-1                                          --\n",
      "|    └─Embedding: 2-1                                   8,192\n",
      "|    └─Embedding: 2-2                                   25,600\n",
      "|    └─ModuleList: 2-3                                  --\n",
      "|    |    └─EncoderLayer: 3-1                           527,104\n",
      "|    |    └─EncoderLayer: 3-2                           527,104\n",
      "|    |    └─EncoderLayer: 3-3                           527,104\n",
      "|    └─Dropout: 2-4                                     --\n",
      "├─Decoder: 1-2                                          --\n",
      "|    └─Embedding: 2-5                                   8,192\n",
      "|    └─Embedding: 2-6                                   25,600\n",
      "|    └─ModuleList: 2-7                                  --\n",
      "|    |    └─DecoderLayer: 3-4                           790,784\n",
      "|    |    └─DecoderLayer: 3-5                           790,784\n",
      "|    |    └─DecoderLayer: 3-6                           790,784\n",
      "|    └─Linear: 2-8                                      8,224\n",
      "|    └─Dropout: 2-9                                     --\n",
      "================================================================================\n",
      "Total params: 4,029,472\n",
      "Trainable params: 4,029,472\n",
      "Non-trainable params: 0\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "├─Encoder: 1-1                                          --\n",
       "|    └─Embedding: 2-1                                   8,192\n",
       "|    └─Embedding: 2-2                                   25,600\n",
       "|    └─ModuleList: 2-3                                  --\n",
       "|    |    └─EncoderLayer: 3-1                           527,104\n",
       "|    |    └─EncoderLayer: 3-2                           527,104\n",
       "|    |    └─EncoderLayer: 3-3                           527,104\n",
       "|    └─Dropout: 2-4                                     --\n",
       "├─Decoder: 1-2                                          --\n",
       "|    └─Embedding: 2-5                                   8,192\n",
       "|    └─Embedding: 2-6                                   25,600\n",
       "|    └─ModuleList: 2-7                                  --\n",
       "|    |    └─DecoderLayer: 3-4                           790,784\n",
       "|    |    └─DecoderLayer: 3-5                           790,784\n",
       "|    |    └─DecoderLayer: 3-6                           790,784\n",
       "|    └─Linear: 2-8                                      8,224\n",
       "|    └─Dropout: 2-9                                     --\n",
       "================================================================================\n",
       "Total params: 4,029,472\n",
       "Trainable params: 4,029,472\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(evaluation.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e5e86-a5ef-4957-a17a-50358a48da41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
